---
title: "Data"
output: 
  html_document:
    theme: flatly
    toc: true
    code_folding: hide
    toc_float: true
---

<style>
body {
  color: #382320 !important;    
}

h1, h2, h3, h4, h5 {
  color: #382320 !important;     
}
</style>

<div class="body-overlay"></div>

<div class="main-container">

<link href="https://fonts.googleapis.com/css2?family=Kranky&display=swap" rel="stylesheet">

<style>
.rat-title {
  font-family: 'Kranky', cursive;
  font-size: 46px;
  font-weight: 400;
  color: #333333;
  letter-spacing: 1px;
  margin-top: 10px;
  margin-bottom: 14px;
}
</style>

<style>
body {
  background-image: url("images/proposal_bg.jpg");
  background-size: cover;
  background-attachment: fixed;
  background-position: center;
  background-repeat: no-repeat;
  opacity: 1;
}

.body-overlay {
  position: fixed;
  top: 0;
  left: 0;
  width: 190%;    
  height: 120%;   
  background: rgba(255,255,255,0.05); 
  z-index: -1;    
  pointer-events: none;
}

.main-container {
  background: rgba(255,255,255,0.75);
  padding: 20px;
  border-radius: 12px;
}
</style>


<h1 class="rat-title">Data</h1>

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(readr)
library(janitor)
library(dplyr)
library(ggplot2)
library(readxl)
library(sf)
library(spdep)
library(tigris)
library(lubridate)
```


We integrated and merged three datasets for our analysis: **Rat Sighting**, **NYC Restaurant Inspection Result**,and **ACS 2019 5-year estimates**. To ensure temporal consistency and spatial alignment across datasets, the following steps were applied.


_Notice: For the merged data and its cleaning process, we didn't include `longitude` and `latitude` because they are not able to be merged on zipcode x year x month level. We left them for Spatial Analysis specifically. For **all** 3 datasets, only records with ZIP codes 10001–11697 were included (notice that NYC zip codes are not cumulative so only zipcodes in this range+overlaps between 3 datasets). For **Rat Sighting** and **NYC Restaurant Inspection Result** datasets, records with dates between 2019-01-01 and 2024-12-31 were included._

```{r,message=FALSE, warning = FALSE}

rats_clean_2019_2024 <- read_csv(
  "data/Rat_Sightings_20251106.csv",
  na = c("NA", "", "0")
) |>
  janitor::clean_names() |>
  # covert datetime to example: "2024-12-31 18:15:58"
  mutate(
    created_datetime = lubridate::parse_date_time(
      created_date,
      orders = "Y b d I:M:S p",
      tz = "America/New_York"
    ),
    created_date_only = as.Date(created_datetime)
  ) |>
  # filter: 2019–2024 and zipcodes 10001-11697
  filter(
    !is.na(created_datetime),
    created_date_only >= as.Date("2019-01-01"),
    created_date_only <= as.Date("2024-12-31")
  ) |>
  mutate(
    incident_zip = incident_zip |>
      as.character() |>
      stringr::str_extract("\\d+") |>
      stringr::str_pad(width = 5, side = "left", pad = "0")
  ) |>
  filter(
    incident_zip >= "10001",
    incident_zip <= "11697"
  ) |>
  dplyr::select(
    dplyr::any_of(c(
      "unique_key", 
      "created_date_only",
      "complaint_type", 
      "descriptor", 
      "status", 
      "resolution_action_updated_date", 
      "location_type", 
      "incident_zip",
      "incident_address", 
      "street_name", 
      "cross_street_1", 
      "cross_street_2", 
      "city", 
      "borough",
      "latitude",
      "longitude",
      "community_board", 
      "council_district", 
      "census_tract", 
      "nta" 
    ))
  ) |>
  # keep for spatial analysis
  filter(
    !is.na(incident_zip),
    !is.na(latitude),
    !is.na(longitude)
  ) |>
  # standardize zipcode, year, and month
  mutate(
    zipcode = incident_zip,
    year    = lubridate::year(created_date_only),
    month   = lubridate::month(created_date_only)
  )

```
## Data Source 1

**[Rat Sighting](https://data.cityofnewyork.us/Social-Services/Rat-Sightings/3q43-55fe/about_data)**: Each row represents one rat sighting report based on the [311 Service Requests](https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/about_data). Key raw fields include complaint date, exact address, borough, zipcodes, and geographic coordinates.

**Data Pre-cleaning steps included:**

- Converted raw timestamps `created_date_only` into standardized datetime (yyyy-mm-dd), then create new variables `year` and `month`.

- Extracted valid 5-digit NYC ZIP codes (10001–11697) `incident_zip`, then create new variable `zipcode`.

- Filtered to observations from 2019-01-01 to 2024-12-31.

- Removed records missing ZIP or geolocation (required for spatial EDA), and keep variables `longitude` and `latitude` for future **Spatial Analysis**.

- We were not interested in all variables of the raw dataset, so we selected for merged data: 

`unique_key`: unique ID represents a single rat sighting report.

`created_date_only`: date of the complaint created without exact time.

`zipcode`: zip codes of the rat sighting complaints.

`year`: year of the rat sighting complaints.

`month`: month of the rat sighting complaints.

`latitude`: the latitude of the specific rat sighting.

`longitude`: the longitude of the specific rat sighting.

```{r,message=FALSE, warning = FALSE}
rat_agg_zip_month_full <- rats_clean_2019_2024 |>
  group_by(zipcode, year, month) |>
  summarize(
    rat_count_zip_month = n_distinct(unique_key),
    .groups = "drop"
  ) |>
  complete(
    zipcode,
    year,
    month,
    fill = list(rat_count_zip_month = 0)
  )
```

**Aggregate Rat Sighting by zip x year x month**, then create a new variable `rat_count_zip_month`: total numbers of rat sightings count of a specific zip by year by month.


```{r,message=FALSE, warning = FALSE}
inspections_clean <- read_csv(
  "data/DOHMH_New_York_City_Restaurant_Inspection_Results.csv",
  na = c("NA", "", "0")
) |>
  clean_names() |>
  remove_empty(c("rows", "cols")) |>
  
  # Standardize ZIP and Dates
  mutate(
    zipcode = zipcode |>
      as.character() |>
      str_extract("\\d{5}") |>   # ensure 5-digit format
      str_pad(width = 5, pad = "0"),
    date = mdy(inspection_date)
  ) |>
  
  # Filter valid records
  filter(
    !is.na(date),
    date >= as.Date("2019-01-01"),
    date <= as.Date("2024-12-31"),

    !is.na(zipcode),
    zipcode >= "10001",
    zipcode <= "11697",

    !is.na(latitude),
    !is.na(longitude),
    !is.na(boro),
    !is.na(violation_code)   # keep only violation records
  ) |>
  
  # Select necessary variables
  dplyr::select(
    restaurant_id = camis,
    dba,
    borough = boro,
    zipcode,
    cuisine_description,
    date,
    action,
    violation_code, violation_description, critical_flag,
    score, grade, grade_date, record_date,
    inspection_type,
    latitude, longitude
  ) |>
  
  # Add Year and Month
  mutate(
    year = year(date),
    month = month(date)
  )
```
## Data Source 2

**[NYC Restaurant Inspection Result](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j/about_data)**: We utilized the NYC Restaurant Inspection Results dataset obtained from NYC Open Data, which compiles sanitation inspection outcomes for food service establishments across New York City. The dataset contains restaurant-level violation records including location, inspection dates, cuisine type, violation codes, and inspection results issued by the Department of Health and Mental Hygiene (DOHMH). This dataset provides an indicator of environmental hygiene conditions that may influence rodent activity.

**Data Pre-cleaning steps included:**
- Extracted valid 5-digit NYC ZIP codes (10001–11697) `zipcode` and padded to valid 5-digit format.

-Raw inspection dates `inspection_date` converted to standardized Date format. Extracted `year` and `month` for temporal trend analysis.

- Retained only observations with non-missing `violation_code`. Inspections showing “No violations observed” were excluded. Removed incomplete geographic records lacking `latitude`/`longitude` or borough values.

- We were not interested in all variables of the raw dataset, so we selected for merged data: 

`restaurant_id`: unique ID of each restaurants.

`zipcode`: zip codes of restaurants.

`year`: year of the Restaurant Inspection and Violations Results.

`month`: month of the Restaurant Inspection and Violations Results.

`latitude`: the latitude of the Restaurants.

`longitude`: the longitude of the Restaurants.



```{r,message=FALSE, warning = FALSE}
restaurant_agg_zip_month_full <- inspections_clean |>
  group_by(zipcode, year, month) |>
  summarise(
    violation_count_zip_month = n(),
    inspection_count_zip_month = n_distinct(restaurant_id, date),
    .groups = "drop"
  ) |>
 complete(
    zipcode,
    year  = 2019:2024,
    month = 1:12,
    fill = list(
      violation_count_zip_month   = 0,
      inspection_count_zip_month = 0
    )
  )
```
**Aggregate NYC Restaurant Inspection Results by zip x year x month**, then create new variables:
`violation_count_zip_month` (total number of recorded violations within each ZIP–year–month) and `inspection_count_zip_month`(total number of recorded inspections within each ZIP–year–month).


```{r,message=FALSE, warning = FALSE}
library(tidycensus)
library(tidyverse)

acs_zip_raw <- get_acs(
  geography = "zip code tabulation area",
  variables = c(
    total_pop   = "B01003_001",
    pov_total   = "B17001_001",
    pov_count   = "B17001_002",
    med_income  = "B19013_001"
  ),
  year   = 2019,
  survey = "acs5",
  geometry = FALSE
)

ses_zip <- acs_zip_raw %>%
  select(GEOID, variable, estimate) %>%
  pivot_wider(
    names_from  = variable,
    values_from = estimate
  ) %>%
  mutate(
    zip = GEOID,
    poverty_rate = pov_count / pov_total,
    population_density = total_pop / 1000,
    median_household_income = med_income / 1000
  )

ses_zip_nyc <- ses_zip %>%
  mutate(zip_num = as.numeric(zip)) %>%
  filter(
    !is.na(zip_num),
    zip_num >= 10001,
    zip_num <= 11697,
    total_pop > 0,
    pov_total > 0
  ) %>%
  select(
    zipcode  = zip_num,
    total_pop,
    poverty_rate,
    population_density,
    median_household_income
  )
```

## Data Source 3

**ACS 2019 5-year estimates**: Area-level socioeconomic indicators were obtained from the 2015–2019 ACS 5-year estimates at the ZIP Code Tabulation Area (ZCTA) level using _tidycensus_ in R. *Notice: We selected the 2015–2019 estimates because the 2019–2023 ACS data were affected by COVID-19-related disruptions and contained substantial missingness, while SES indicators remain relatively stable over time.

**Data Pre-cleaning and preparation**:

- Extracted valid 5-digit NYC ZIP codes (10001–11697) `zipcode` and padded to valid 5-digit format.

- We focused on variables that are most relevant to restaurant sanitation and the environmental conditions influencing rat activity: 

`zipcode`: zipcodes of the NYC.

`total_pop`: total population of the specific zipcode.

`pov_count`: the subset of individuals living below the U.S. federal poverty threshold as defined by the ACS

`pov_total`: the total civilian population within the ZIP Code Tabulation Area eligible for poverty status determination

`med_income`:the midpoint of the household income distribution where 50% of households earn more and 50% earn less

We also realized that counts describe size and may cause bias (For example, high rodent risk may still exist in smaller-population neighborhoods, and count-based socioeconomic metrics would underestimate such disparities.), but rates and densities describe risk and environment — which are what we want to study. Hence, we created new zip -level variables: 

$pov\_rate = \frac{pov\_count}{pov\_total}$: represents the proportion of residents living below the federal poverty threshold within each ZIP Code Tabulation Area

$population\_density = \frac{total\_pop}{1000}$: expresses the concentration of residents per ZIP code, measured as total population per 1,000 residents, serving as an indicator of urbanization and built environment crowding.

$median\_household\_income = \frac{med\_income}{1000}$: reflects the neighborhood’s economic resource level. med_income denotes the ACS-estimated median household income in USD, scaled per $1,000 for interpretability in modeling and descriptive statistics.

```{r,message=FALSE, warning = FALSE}
rat_fixed <- rat_agg_zip_month_full |>
  mutate(zipcode = as.character(zipcode))

restaurant_fixed <- restaurant_agg_zip_month_full |>
  mutate(zipcode = as.character(zipcode))

ses_fixed <- ses_zip_nyc |>
  mutate(zipcode = as.character(zipcode))

common_zips <- Reduce(
  intersect,
  list(
    rat_fixed$zipcode,
    restaurant_fixed$zipcode,
    ses_fixed$zipcode
  )
)

rat_filtered <- rat_fixed |>
  filter(zipcode %in% common_zips)

restaurant_filtered <- restaurant_fixed |>
  filter(zipcode %in% common_zips)

ses_filtered <- ses_fixed |>
  filter(zipcode %in% common_zips)

df_merged <- rat_filtered |>
  inner_join(restaurant_filtered,
             by = c("zipcode", "year", "month")) |>
  inner_join(ses_filtered,
             by = "zipcode")

write_csv(df_merged, "./data/zip_year_month_merged.csv")
```

## Merge 3 datasets by zipcode x year x month
In the merged dataset, we included variables: `zipcode`, `year`, `month`, `rat_count_zip_month`, `violation_count_zip_month`, `inspection_count_zip_month`, `total_pop`, `poverty_rate`, `population_density`. 

## Export
We exported the merged dataset as csv file zip_year_month_merged.

</div>